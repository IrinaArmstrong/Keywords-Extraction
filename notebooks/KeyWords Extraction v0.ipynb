{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number CPU: 12\n"
     ]
    }
   ],
   "source": [
    "# Basic\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "import more_itertools\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from collections import defaultdict, Counter\n",
    "from typing import (List, Dict, Any, NoReturn, \n",
    "                    Tuple, Optional, Union)\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing_logging import install_mp_handler\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Number CPU: {multiprocessing.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W2V\n",
    "import spacy\n",
    "import pymorphy2\n",
    "from gensim.utils import any2utf8, to_utf8\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.phrases import Phrases\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from gensim.models.phrases import Phrases, npmi_scorer\n",
    "from gensim.models import word2vec, keyedvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"..\")\n",
    "DATA_DIR  = BASE_DIR / \"data\"\n",
    "LISTS_DIR  = BASE_DIR / \"lists\"\n",
    "MODEL_DIR  = BASE_DIR / \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c421bacc5ad483f8f4b42b26cfb5820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data part of shape: (3944, 10)\n",
      "Data part of shape: (9200, 10)\n",
      "\n",
      "All data of shape: (13144, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incident</th>\n",
       "      <th>req_reason</th>\n",
       "      <th>req_reg_datetime</th>\n",
       "      <th>req_num</th>\n",
       "      <th>msg</th>\n",
       "      <th>product</th>\n",
       "      <th>subproduct</th>\n",
       "      <th>subject</th>\n",
       "      <th>s_subject</th>\n",
       "      <th>day_of_the_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>Инцидент</td>\n",
       "      <td>2020-11-05 11:27:21</td>\n",
       "      <td>2011050726933001</td>\n",
       "      <td>здравствуйте здравствуйте я застрахованное лиц...</td>\n",
       "      <td>Страхование</td>\n",
       "      <td>.Страховой случай</td>\n",
       "      <td>Консультация по продуктам и обслуживанию</td>\n",
       "      <td>Разъяснения (условия, сроки, статусы рассмотре...</td>\n",
       "      <td>[310]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>Инцидент</td>\n",
       "      <td>2020-11-19 15:27:04</td>\n",
       "      <td>2011190004665301</td>\n",
       "      <td>Куда  #ТОПОНИМ  мой аватар Ну если не понял то...</td>\n",
       "      <td>Онлайн-сервисы</td>\n",
       "      <td>Функционирование МБ/СБОЛ/МП</td>\n",
       "      <td>Работа в системе</td>\n",
       "      <td>Информация по возможностям/ограничениям</td>\n",
       "      <td>[324]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>Инцидент</td>\n",
       "      <td>2020-11-20 13:16:35</td>\n",
       "      <td>2011200083620001</td>\n",
       "      <td>меня зовут  #ФИО  здравствуйте здравствуйте у ...</td>\n",
       "      <td>Физ. лица - иные услуги/продукты</td>\n",
       "      <td>Кредитная история (БКИ)</td>\n",
       "      <td>Вопросы по отчету</td>\n",
       "      <td>Отчет не поступил/поступил с ошибкой</td>\n",
       "      <td>[325]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OTHER</td>\n",
       "      <td>Инцидент</td>\n",
       "      <td>2020-11-21 19:29:17</td>\n",
       "      <td>2011210190303001</td>\n",
       "      <td>#ФИО  здравствуйте добрый день я вас слушаю я...</td>\n",
       "      <td>Онлайн-сервисы</td>\n",
       "      <td>Функционирование МБ/СБОЛ/МП</td>\n",
       "      <td>Работа в системе</td>\n",
       "      <td>Информация по возможностям/ограничениям</td>\n",
       "      <td>[326]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IM0104549077</td>\n",
       "      <td>Инцидент</td>\n",
       "      <td>2020-11-20 13:40:55</td>\n",
       "      <td>2011200086706501</td>\n",
       "      <td>меня зовут  #ФИО  здравствуйте  #ФИО  добрый д...</td>\n",
       "      <td>Онлайн-сервисы</td>\n",
       "      <td>Функционирование МБ/СБОЛ/МП</td>\n",
       "      <td>Работа в системе</td>\n",
       "      <td>Некорректная работа Мобильного Приложения СБОЛ</td>\n",
       "      <td>[325]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       incident req_reason     req_reg_datetime           req_num  \\\n",
       "0         OTHER   Инцидент  2020-11-05 11:27:21  2011050726933001   \n",
       "1         OTHER   Инцидент  2020-11-19 15:27:04  2011190004665301   \n",
       "2         OTHER   Инцидент  2020-11-20 13:16:35  2011200083620001   \n",
       "3         OTHER   Инцидент  2020-11-21 19:29:17  2011210190303001   \n",
       "4  IM0104549077   Инцидент  2020-11-20 13:40:55  2011200086706501   \n",
       "\n",
       "                                                 msg  \\\n",
       "0  здравствуйте здравствуйте я застрахованное лиц...   \n",
       "1  Куда  #ТОПОНИМ  мой аватар Ну если не понял то...   \n",
       "2  меня зовут  #ФИО  здравствуйте здравствуйте у ...   \n",
       "3   #ФИО  здравствуйте добрый день я вас слушаю я...   \n",
       "4  меня зовут  #ФИО  здравствуйте  #ФИО  добрый д...   \n",
       "\n",
       "                            product                   subproduct  \\\n",
       "0                       Страхование            .Страховой случай   \n",
       "1                    Онлайн-сервисы  Функционирование МБ/СБОЛ/МП   \n",
       "2  Физ. лица - иные услуги/продукты      Кредитная история (БКИ)   \n",
       "3                    Онлайн-сервисы  Функционирование МБ/СБОЛ/МП   \n",
       "4                    Онлайн-сервисы  Функционирование МБ/СБОЛ/МП   \n",
       "\n",
       "                                    subject  \\\n",
       "0  Консультация по продуктам и обслуживанию   \n",
       "1                          Работа в системе   \n",
       "2                         Вопросы по отчету   \n",
       "3                          Работа в системе   \n",
       "4                          Работа в системе   \n",
       "\n",
       "                                           s_subject day_of_the_year  \n",
       "0  Разъяснения (условия, сроки, статусы рассмотре...           [310]  \n",
       "1            Информация по возможностям/ограничениям           [324]  \n",
       "2               Отчет не поступил/поступил с ошибкой           [325]  \n",
       "3            Информация по возможностям/ограничениям           [326]  \n",
       "4     Некорректная работа Мобильного Приложения СБОЛ           [325]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = []\n",
    "for fn in tqdm_notebook(glob.glob(str(DATA_DIR / \"*.csv\"))):\n",
    "    df_part = pd.read_csv(fn, sep=';', encoding='utf-8')\n",
    "    print(f\"Data part of shape: {df_part.shape}\")\n",
    "    df.append(df_part)\n",
    "df = pd.concat(df).reset_index(drop=True)\n",
    "print(f\"All data of shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_opener(filename: str) -> str:\n",
    "    with open(filename, 'rt', encoding='utf-8-sig') as src:\n",
    "        file = src.read()\n",
    "    return \"|\".join([x for x in file.split('\\n') if x])\n",
    "\n",
    "\n",
    "class DataPreprocessorLemmatizer:\n",
    "\n",
    "    text_features = ['msg']\n",
    "    stopgrams = [\n",
    "             'CONJ',   # союз\n",
    "             'PRCL',   # частица\n",
    "             'PRED',   # предикатив\n",
    "             'NPRO',   # местоимение-сущ.\n",
    "             'INTJ',   # междометие\n",
    "             'Erro',   # ошибка\n",
    "             'Dist',   # искажение\n",
    "             'Ques',   # вопросительное слово\n",
    "             'Dmns',   # указательное слово\n",
    "             'Prnt'   # вводное слово\n",
    "            ]\n",
    "\n",
    "    def __init__(self, multipocess: bool, num_processors: int=16, chunksize: int=100, \n",
    "                intro_words_path: str = './lists'):\n",
    "        # Language parsers\n",
    "        self.__morph = pymorphy2.MorphAnalyzer()\n",
    "        self.__nlp = spacy.blank('ru')\n",
    "        # Multiprocessing params\n",
    "        self.__multipocess = multipocess\n",
    "        self.__num_processors = num_processors\n",
    "        self.__chunksize = chunksize\n",
    "        # Cleaning utils\n",
    "        self.__intro_words = file_opener(os.path.join(intro_words_path, 'intro.txt'))\n",
    "        self.__nltk_stopwords = file_opener(os.path.join(intro_words_path, 'NLTK_stopwords.txt')).split(\"|\")\n",
    "\n",
    "    def get_stopwords(self):\n",
    "        \"\"\" \n",
    "        Check intro-words list.\n",
    "        \"\"\"\n",
    "        return self.__nltk_stopwords\n",
    "\n",
    "    def get_intro_words(self):\n",
    "        \"\"\" \n",
    "        Check intro-words list.\n",
    "        \"\"\"\n",
    "        return self.__intro_words\n",
    "    \n",
    "    def get_analyzer(self):\n",
    "        \"\"\"\n",
    "        Allow to access to Pymorphy Analyzer instance.\n",
    "        \"\"\"\n",
    "        return self.__morph\n",
    "\n",
    "    \n",
    "    def _process_text(self, text: str):\n",
    "        \"\"\" \n",
    "        Process single text and return list of tokens.\n",
    "        \"\"\"\n",
    "        if pd.isna(text):\n",
    "            return []\n",
    "       # Pre-processing part \n",
    "        text = [str(token).lower()\n",
    "                for token in self.__nlp.make_doc(text)\n",
    "                if (token and token.is_alpha and len(str(token.text)) > 2 and ~token.is_stop)]\n",
    "        # Processing part\n",
    "        clean_text = []\n",
    "        for token in text:\n",
    "            token = self.__morph.parse(str(token).lower())[0]\n",
    "            if ((token.normal_form not in self.__nltk_stopwords) \n",
    "                and (token.normal_form not in self.__intro_words)\n",
    "                and all([tag not in token.tag for tag in self.stopgrams])):\n",
    "                clean_text.append(token.normal_form)\n",
    "        return clean_text\n",
    "    \n",
    "\n",
    "    def process_texts(self, texts: List[str]):\n",
    "        \"\"\" \n",
    "        Process list of texts and return list of lists of tokens.\n",
    "        \"\"\"\n",
    "        if self.__multipocess:\n",
    "            with multiprocessing.Pool(self.__num_processors) as pool:\n",
    "                processed_texts = list(tqdm_notebook(pool.imap(self._process_text, texts, \n",
    "                                                               chunksize=self.__chunksize), \n",
    "                                                     total=len(texts)))\n",
    "            return processed_texts\n",
    "        else:\n",
    "            return [self._process_text(text) for text in tqdm_notebook(texts)]\n",
    "        \n",
    "\n",
    "\n",
    "    def process(self, data: pd.DataFrame,\n",
    "                features_cols: Optional[List[str]] = None, copy: bool=True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Preprocess text for language modelling.\n",
    "         - clean introduction words, numbers and small prefixes;\n",
    "         - tokenize and lemmatize texts;\n",
    "        \"\"\"\n",
    "        logging.info(\"Text processing started.\")\n",
    "        if not features_cols:\n",
    "            features_cols = self.text_features\n",
    "\n",
    "        for col_name in features_cols:\n",
    "            logging.info(f\"Processing '{col_name}' column...\")\n",
    "            data_processed = self.process_texts(data[col_name].fillna(\"\").to_list())\n",
    "            if not copy:\n",
    "                data[col_name] = data_processed\n",
    "            else:\n",
    "                data[col_name + \"_proc\"] = data_processed\n",
    "\n",
    "        logging.info(\"Text preprocessing finished.\")\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-18 18:59:45,028 - pymorphy2.opencorpora_dict.wrapper - INFO - Loading dictionaries from C:\\Users\\airen\\Anaconda3\\envs\\pycharmenv\\lib\\site-packages\\pymorphy2_dicts\\data\n",
      "2021-07-18 18:59:45,168 - pymorphy2.opencorpora_dict.wrapper - INFO - format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168\n",
      "2021-07-18 18:59:45,198 - pymorphy2.opencorpora_dict.wrapper - INFO - Loading dictionaries from C:\\Users\\airen\\Anaconda3\\envs\\pycharmenv\\lib\\site-packages\\pymorphy2_dicts\\data\n",
      "2021-07-18 18:59:45,307 - pymorphy2.opencorpora_dict.wrapper - INFO - format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168\n"
     ]
    }
   ],
   "source": [
    "processor = DataPreprocessorLemmatizer(multipocess=False,\n",
    "                                       num_processors=8, chunksize=200,\n",
    "                                       intro_words_path=str(LISTS_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-18 18:59:45,934 - root - INFO - Text processing started.\n",
      "2021-07-18 18:59:45,936 - root - INFO - Processing 'msg' column...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788f8594edf14a2999f008cce0bd3b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-18 19:06:50,554 - root - INFO - Text preprocessing finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 7min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = processor.process(data=df, features_cols=['msg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "здравствуйте здравствуйте я застрахованное лицо я хотела бы узнать договор полиса и дата оплаты страховой премии мне по поводу кража у меня украли  #ЧИСЛО  тысяч мошенники я как бы чтоб страховой написать заявление то есть подать на страховой случай я правильно понимаю да да да мне должны указать договор полис я по телефону это все как то оплачивала договор вам оплатить нужно правильно понимаю нет у меня мошенники сняли  #ЧИСЛО  тысяч и как бы я хочу в страховую службу написать заявление мне нужно указать договор полис и дата оплаты страховой премии когда оплачивалась то есть вам нужен номер договора да номер договора мы не сообщаем как же мне заявление для по поводу кражи вы сказали вам звонить в сбербанк щас сижу так одна минута деньги  #ЧИСЛО  когда позвонит еще послан от обратиться этот номер договора номер договора говорит не сообщаем а потом и одну минуточку подождите не сообщаем а потом что мне делать и для документации не ладно сейчас минуточку подождите сейчас выясню я уже сказала уточните пожалуйста а где именно вам нужно указать номер договора заявление о наступлении события имеющие признаки страхового случая сбербанк страхование одна минута по техническим причинам отсутствует возможность предоставить интересующую вас информацию приносим извинения за доставленные неудобства приносим просим перезвони  #ТОПОНИМ  не поняла что то слово по техническим причинам отсутствует возможность предоставить интересующую вас информацию приносим извинения за доставленные неудобства и просим перезвонить вас позднее а что сбербанк честно говоря мне нужно час допустим заявление это но к сожалению нет сейчас технической возможности предоставить информацию в алло а если попозже перезвоню будет техническая возможность по позже можно будет перезвонить всего доброго до свидания\n",
      "['застраховать', 'лицо', 'хотеть', 'узнать', 'договор', 'полис', 'дата', 'оплата', 'страховой', 'премия', 'повод', 'кража', 'украсть', 'тысяча', 'мошенник', 'страховой', 'написать', 'заявление', 'подать', 'страховой', 'случай', 'правильно', 'понимать', 'должный', 'указать', 'договор', 'полис', 'телефон', 'весь', 'оплачивать', 'договор', 'оплатить', 'правильно', 'понимать', 'мошенник', 'снять', 'тысяча', 'хотеть', 'страховой', 'служба', 'написать', 'заявление', 'указать', 'договор', 'полис', 'дата', 'оплата', 'страховой', 'премия', 'оплачиваться', 'нужный', 'номер', 'договор', 'номер', 'договор', 'сообщать', 'заявление', 'повод', 'кража', 'сказать', 'звонить', 'сбербанк', 'щас', 'сидеть', 'деньга', 'позвонить', 'послать', 'обратиться', 'номер', 'договор', 'номер', 'договор', 'говорить', 'сообщать', 'минуточка', 'подождать', 'сообщать', 'делать', 'документация', 'ладный', 'минуточка', 'подождать', 'выяснить', 'сказать', 'уточнить', 'указать', 'номер', 'договор', 'заявление', 'наступление', 'событие', 'иметь', 'признак', 'страховой', 'случай', 'сбербанк', 'страхование', 'технический', 'причина', 'отсутствовать', 'возможность', 'предоставить', 'интересовать', 'информация', 'приносить', 'извинение', 'доставить', 'неудобство', 'приносить', 'просить', 'перезвонить', 'понять', 'слово', 'технический', 'причина', 'отсутствовать', 'возможность', 'предоставить', 'интересовать', 'информация', 'приносить', 'извинение', 'доставить', 'неудобство', 'просить', 'перезвонить', 'поздний', 'сбербанк', 'честно', 'говорить', 'час', 'допустить', 'заявление', 'технический', 'возможность', 'предоставить', 'информация', 'поздний', 'перезвонить', 'технический', 'возможность', 'поздний', 'перезвонить']\n",
      "--------------\n",
      "Куда  #ТОПОНИМ  мой аватар Ну если не понял то позови оператора !  #ФИО  , где шаблоны операций и мой аватар , который всегда был Здравствуйте! Проверяю, скоро вернусь Войдите в приложение сегодня после  #ЧИСЛО : #ЧИСЛО  по МСК, сейчас временные ограничения\n",
      "['аватар', 'понять', 'позвать', 'оператор', 'шаблон', 'операция', 'аватар', 'который', 'проверять', 'скоро', 'вернуться', 'войти', 'приложение', 'сегодня', 'мск', 'временной', 'ограничение']\n",
      "--------------\n",
      "меня зовут  #ФИО  здравствуйте здравствуйте у меня вопрос такого характера сбербанк онлайн открываю мне нужна кредитная история и почему то не пишет пишет на портале у вас нет доступа к данной операции выступил данную операцию сбербанк онлайн на телефоне или на компьютере  #ФИО   #ФИО  на компьютере на компьютере пару минут ожидайте спасибо за ожидание да действительно сейчас недоступна по той причине что идут технологические работы по вашему сбербанк онлайн так должны закончится после  #ЧИСЛО  часов сегодняшнего дня по  #ТОПОНИМ  все понятно я то думала адресная какая то отказ доступа именно мне спасибо угу спасибо всего доброго угу до свидания\n",
      "['звать', 'вопрос', 'характер', 'сбербанк', 'онлайн', 'открывать', 'нужный', 'кредитный', 'история', 'писать', 'писать', 'портал', 'доступ', 'дать', 'операция', 'выступить', 'данный', 'операция', 'сбербанк', 'онлайн', 'телефон', 'компьютер', 'компьютер', 'компьютер', 'пара', 'ожидать', 'ожидание', 'действительно', 'недоступный', 'причина', 'идти', 'технологический', 'работа', 'ваш', 'сбербанк', 'онлайн', 'должный', 'закончиться', 'часы', 'сегодняшний', 'весь', 'думать', 'адресный', 'отказ', 'доступ']\n",
      "--------------\n",
      " #ФИО  здравствуйте добрый день я вас слушаю я вот захожу в свой сбербанк приложение и какая то код ошибки  #ЧИСЛО  ноль один времени что то недоступно не работает и сказали позвонить в этот на вам  #ФИО  минута но к сожалению сейчас ведутся технические ра просим вас перезайти в данное приложение после  #ЧИСЛО  вечера по московскому времени ага хорошо понял всего доброго до свидания спасибо до свидания\n",
      "['слушать', 'заходить', 'свой', 'сбербанк', 'приложение', 'код', 'ошибка', 'ноль', 'время', 'недоступный', 'работать', 'сказать', 'позвонить', 'вестись', 'технический', 'просить', 'перезайти', 'данный', 'приложение', 'московский', 'время', 'понять']\n",
      "--------------\n",
      "меня зовут  #ФИО  здравствуйте  #ФИО  добрый день вы знаете хочу вас спросить вот сегодня с утра делал переводы в сбербанке онлайн и почему то в истории я переводила за автоплатеж доплачивала а в истории они не отображаются хотя деньги с карты ушли поняла вас минуту сейчас все проверим и все я увижу да  #ФИО   #ФИО  а информация не отражена в истории в связи с тем что на данный момент проводятся технологические работы в личном кабинете они будут завершены после  #ЧИСЛО  часов по  #ТОПОНИМ  в это время сможете проверить конечно все спасибо большое тоже перепугалась ага спасибо до свидания не переживайте хорошего дня\n",
      "['звать', 'хотеть', 'спросить', 'сегодня', 'делать', 'перевод', 'сбербанк', 'онлайн', 'история', 'переводить', 'автоплатёж', 'доплачивать', 'история', 'отображаться', 'деньга', 'карта', 'уйти', 'понять', 'весь', 'проверить', 'весь', 'увидеть', 'информация', 'отразить', 'история', 'связь', 'данный', 'момент', 'проводиться', 'технологический', 'работа', 'личный', 'кабинет', 'завершить', 'часы', 'время', 'смочь', 'проверить', 'весь', 'большой', 'перепугаться', 'переживать', 'хороший']\n"
     ]
    }
   ],
   "source": [
    "for i, row in df[['msg', 'msg_proc']].head().iterrows():\n",
    "    print(\"--------------\")\n",
    "    print(f\"{row['msg']}\\n{row['msg_proc']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bigrammer:\n",
    "    \n",
    "    def __init__(self, phrase_model=None):\n",
    "        self.__phrase_model = phrase_model\n",
    "    \n",
    "    def train(self, texts: List[List[str]], \n",
    "              min_count: int, threshold: float,\n",
    "             to_save: bool, save_path: str=\".\", phrases_fn: str=\"phrases.pkl\"):\n",
    "        \"\"\"\n",
    "        Train gensim Phrases model with NPMI scorer.\n",
    "        :param texts - The training corpus must be a sequence of sentences,\n",
    "                        with each sentence a list of tokens.\n",
    "        :param min_count – Ignore all words and bigrams with total \n",
    "                            collected count lower than this value.\n",
    "        :param threshold – Represent a score threshold for forming \n",
    "                            the phrases (higher means fewer phrases). \n",
    "                            A phrase of words a followed by b is accepted if the score of \n",
    "                            the phrase is greater than threshold. \n",
    "                            For NPMI scorer is in the range -1 to 1.\n",
    "        \"\"\"\n",
    "        logging.info(\"Training bigrammer started.\")\n",
    "        self.__phrase_model = Phrases(texts, min_count=min_count, \n",
    "                               threshold=threshold, scoring='npmi')\n",
    "        logging.info(\"Training bigrammer finished.\")\n",
    "        if to_save:\n",
    "            self.__phrase_model.save(os.path.join(save_path, phrases_fn))\n",
    "            if os.path.isfile(os.path.join(save_path, phrases_fn)):\n",
    "                logging.info(f\"Bigrammer model successfully saved to: {os.path.join(save_path, phrases_fn)}\")\n",
    "        return self\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, save_path: str, phrases_fn: str) -> object:\n",
    "        \"\"\"\n",
    "        Load pre-trained model from file and init.\n",
    "        \"\"\"\n",
    "        if os.path.isfile(os.path.join(save_path, phrases_fn)):\n",
    "            logging.info(f\"Bigrammer model loading from: {os.path.join(save_path, phrases_fn)}\")\n",
    "        phrase_model = Phrases.load(os.path.join(save_path, phrases_fn))\n",
    "        logging.info(f\"Bigrammer model successfully loaded.\")\n",
    "        return cls(phrase_model=phrase_model)\n",
    "    \n",
    "    \n",
    "    def create_bigramms(self, texts: List[List[str]]) -> List[List[str]]:\n",
    "        \"\"\"\n",
    "        Create bi-gramms from given text data, already splitted.\n",
    "        \"\"\"\n",
    "        return [self.__phrase_model[text] if len(text) > 0 \n",
    "                else [] for text in tqdm_notebook(texts)]\n",
    "    \n",
    "    \n",
    "    def process(self, data: pd.DataFrame,\n",
    "                text_col: str, copy: bool=True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create bi-gramms from given column in dataframe.\n",
    "        \"\"\"\n",
    "        logging.info(f\"Bigramms creation for texts in column {text_col} started\")\n",
    "        data_processed = self.create_bigramms(data[text_col].fillna(\"\").to_list())\n",
    "        if not copy:\n",
    "            data[text_col] = data_processed\n",
    "        else:\n",
    "            data[text_col + \"_bigramms\"] = data_processed\n",
    "\n",
    "        logging.info(\"Bigramms creation finished.\")\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def get_vocab(self) -> Dict[bytes, int]:\n",
    "        logging.info(f\"Bigrammer vocab size: {len(self.__phrase_model.vocab)}\")\n",
    "        return self.__phrase_model.vocab\n",
    "    \n",
    "    \n",
    "    def get_phraser(self) -> Phrases:\n",
    "        return self.__phrase_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-18 19:51:07,257 - root - INFO - Training bigrammer started.\n",
      "2021-07-18 19:51:07,257 - gensim.models.phrases - INFO - collecting all words and their counts\n",
      "2021-07-18 19:51:07,258 - gensim.models.phrases - INFO - PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2021-07-18 19:51:08,526 - gensim.models.phrases - INFO - PROGRESS: at sentence #10000, processed 873920 words and 251328 word types\n",
      "2021-07-18 19:51:08,949 - gensim.models.phrases - INFO - collected 303577 word types from a corpus of 1148128 words (unigram + bigrams) and 13144 sentences\n",
      "2021-07-18 19:51:08,950 - gensim.models.phrases - INFO - using 303577 counts as vocab in Phrases<0 vocab, min_count=5, threshold=0.3, max_vocab_size=40000000>\n",
      "2021-07-18 19:51:08,950 - root - INFO - Training bigrammer finished.\n",
      "2021-07-18 19:51:08,951 - root - INFO - Bigrammer vocab size: 303577\n"
     ]
    }
   ],
   "source": [
    "bigrammer = Bigrammer().train(df['msg_proc'].to_list(),\n",
    "                             min_count=5, threshold=0.3,\n",
    "                             to_save=False)\n",
    "bi_vocab = bigrammer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigramms in vocab: 288359 from 303577 which is 94.98710376609559\n",
      "\n",
      "застраховать --> 135\n",
      "лицо --> 733\n",
      "застраховать_лицо --> 7\n",
      "хотеть --> 7220\n",
      "лицо_хотеть --> 4\n",
      "узнать --> 2319\n",
      "хотеть_узнать --> 1013\n",
      "договор --> 681\n",
      "узнать_договор --> 2\n",
      "полис --> 516\n",
      "договор_полис --> 4\n",
      "дата --> 2175\n"
     ]
    }
   ],
   "source": [
    "bigramms = [k for k in bi_vocab.keys() if \"_\" in k.decode('utf-8')]\n",
    "print(f\"Bigramms in vocab: {len(bigramms)} from {len(bi_vocab)} which is {100*len(bigramms)/len(bi_vocab)}\\n\")\n",
    "\n",
    "for i, (k, v) in enumerate(bi_vocab.items()):\n",
    "    print(f\"{k.decode('utf-8')} --> {v}\")\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-18 19:51:09,331 - root - INFO - Bigramms creation for texts in column msg_proc started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8e691f08ec4f038b4b612cccccc548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-18 19:51:13,444 - root - INFO - Bigramms creation finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 4.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = bigrammer.process(df, text_col='msg_proc', copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "здравствуйте здравствуйте я застрахованное лицо я хотела бы узнать договор полиса и дата оплаты страховой премии мне по поводу кража у меня украли  #ЧИСЛО  тысяч мошенники я как бы чтоб страховой написать заявление то есть подать на страховой случай я правильно понимаю да да да мне должны указать договор полис я по телефону это все как то оплачивала договор вам оплатить нужно правильно понимаю нет у меня мошенники сняли  #ЧИСЛО  тысяч и как бы я хочу в страховую службу написать заявление мне нужно указать договор полис и дата оплаты страховой премии когда оплачивалась то есть вам нужен номер договора да номер договора мы не сообщаем как же мне заявление для по поводу кражи вы сказали вам звонить в сбербанк щас сижу так одна минута деньги  #ЧИСЛО  когда позвонит еще послан от обратиться этот номер договора номер договора говорит не сообщаем а потом и одну минуточку подождите не сообщаем а потом что мне делать и для документации не ладно сейчас минуточку подождите сейчас выясню я уже сказала уточните пожалуйста а где именно вам нужно указать номер договора заявление о наступлении события имеющие признаки страхового случая сбербанк страхование одна минута по техническим причинам отсутствует возможность предоставить интересующую вас информацию приносим извинения за доставленные неудобства приносим просим перезвони  #ТОПОНИМ  не поняла что то слово по техническим причинам отсутствует возможность предоставить интересующую вас информацию приносим извинения за доставленные неудобства и просим перезвонить вас позднее а что сбербанк честно говоря мне нужно час допустим заявление это но к сожалению нет сейчас технической возможности предоставить информацию в алло а если попозже перезвоню будет техническая возможность по позже можно будет перезвонить всего доброго до свидания\n",
      "['застраховать_лицо', 'хотеть_узнать', 'договор', 'полис', 'дата', 'оплата', 'страховой', 'премия', 'повод', 'кража', 'украсть', 'тысяча', 'мошенник', 'страховой', 'написать_заявление', 'подать', 'страховой_случай', 'правильно_понимать', 'должный', 'указать', 'договор', 'полис', 'телефон', 'весь', 'оплачивать', 'договор', 'оплатить', 'правильно_понимать', 'мошенник', 'снять', 'тысяча', 'хотеть', 'страховой', 'служба', 'написать_заявление', 'указать', 'договор', 'полис', 'дата', 'оплата', 'страховой', 'премия', 'оплачиваться', 'нужный', 'номер', 'договор', 'номер', 'договор', 'сообщать', 'заявление', 'повод', 'кража', 'сказать', 'звонить', 'сбербанк', 'щас', 'сидеть', 'деньга', 'позвонить', 'послать', 'обратиться', 'номер', 'договор', 'номер', 'договор', 'говорить', 'сообщать', 'минуточка_подождать', 'сообщать', 'делать', 'документация', 'ладный', 'минуточка_подождать', 'выяснить', 'сказать', 'уточнить', 'указать', 'номер', 'договор', 'заявление', 'наступление', 'событие', 'иметь', 'признак', 'страховой_случай', 'сбербанк', 'страхование', 'технический_причина', 'отсутствовать_возможность', 'предоставить_интересовать', 'информация', 'приносить_извинение', 'доставить_неудобство', 'приносить', 'просить', 'перезвонить', 'понять', 'слово', 'технический_причина', 'отсутствовать_возможность', 'предоставить_интересовать', 'информация', 'приносить_извинение', 'доставить_неудобство', 'просить', 'перезвонить_поздний', 'сбербанк', 'честно_говорить', 'час', 'допустить', 'заявление', 'технический', 'возможность_предоставить', 'информация', 'поздний', 'перезвонить', 'технический', 'возможность', 'поздний', 'перезвонить']\n",
      "--------------\n",
      "Куда  #ТОПОНИМ  мой аватар Ну если не понял то позови оператора !  #ФИО  , где шаблоны операций и мой аватар , который всегда был Здравствуйте! Проверяю, скоро вернусь Войдите в приложение сегодня после  #ЧИСЛО : #ЧИСЛО  по МСК, сейчас временные ограничения\n",
      "['аватар', 'понять', 'позвать_оператор', 'шаблон', 'операция', 'аватар', 'который', 'проверять', 'скоро_вернуться', 'войти', 'приложение', 'сегодня', 'мск', 'временной_ограничение']\n",
      "--------------\n",
      "меня зовут  #ФИО  здравствуйте здравствуйте у меня вопрос такого характера сбербанк онлайн открываю мне нужна кредитная история и почему то не пишет пишет на портале у вас нет доступа к данной операции выступил данную операцию сбербанк онлайн на телефоне или на компьютере  #ФИО   #ФИО  на компьютере на компьютере пару минут ожидайте спасибо за ожидание да действительно сейчас недоступна по той причине что идут технологические работы по вашему сбербанк онлайн так должны закончится после  #ЧИСЛО  часов сегодняшнего дня по  #ТОПОНИМ  все понятно я то думала адресная какая то отказ доступа именно мне спасибо угу спасибо всего доброго угу до свидания\n",
      "['звать', 'вопрос', 'характер', 'сбербанк_онлайн', 'открывать', 'нужный', 'кредитный_история', 'писать', 'писать', 'портал', 'доступ', 'дать', 'операция', 'выступить', 'данный', 'операция', 'сбербанк_онлайн', 'телефон', 'компьютер_компьютер', 'компьютер', 'пара_ожидать', 'ожидание_действительно', 'недоступный', 'причина', 'идти_технологический', 'работа', 'ваш', 'сбербанк_онлайн', 'должный_закончиться', 'часы', 'сегодняшний', 'весь', 'думать', 'адресный', 'отказ', 'доступ']\n",
      "--------------\n",
      " #ФИО  здравствуйте добрый день я вас слушаю я вот захожу в свой сбербанк приложение и какая то код ошибки  #ЧИСЛО  ноль один времени что то недоступно не работает и сказали позвонить в этот на вам  #ФИО  минута но к сожалению сейчас ведутся технические ра просим вас перезайти в данное приложение после  #ЧИСЛО  вечера по московскому времени ага хорошо понял всего доброго до свидания спасибо до свидания\n",
      "['слушать', 'заходить', 'свой', 'сбербанк', 'приложение', 'код_ошибка', 'ноль', 'время', 'недоступный', 'работать', 'сказать', 'позвонить', 'вестись_технический', 'просить', 'перезайти', 'данный', 'приложение', 'московский_время', 'понять']\n",
      "--------------\n",
      "меня зовут  #ФИО  здравствуйте  #ФИО  добрый день вы знаете хочу вас спросить вот сегодня с утра делал переводы в сбербанке онлайн и почему то в истории я переводила за автоплатеж доплачивала а в истории они не отображаются хотя деньги с карты ушли поняла вас минуту сейчас все проверим и все я увижу да  #ФИО   #ФИО  а информация не отражена в истории в связи с тем что на данный момент проводятся технологические работы в личном кабинете они будут завершены после  #ЧИСЛО  часов по  #ТОПОНИМ  в это время сможете проверить конечно все спасибо большое тоже перепугалась ага спасибо до свидания не переживайте хорошего дня\n",
      "['звать', 'хотеть_спросить', 'сегодня', 'делать_перевод', 'сбербанк_онлайн', 'история', 'переводить', 'автоплатёж', 'доплачивать', 'история', 'отображаться', 'деньга', 'карта', 'уйти', 'понять', 'весь', 'проверить', 'весь', 'увидеть', 'информация', 'отразить', 'история', 'связь', 'данный_момент', 'проводиться_технологический', 'работа', 'личный_кабинет', 'завершить', 'часы', 'время', 'смочь_проверить', 'весь_большой', 'перепугаться', 'переживать', 'хороший']\n"
     ]
    }
   ],
   "source": [
    "for i, row in df[['msg', 'msg_proc_bigramms']].head().iterrows():\n",
    "    print(\"--------------\")\n",
    "    print(f\"{row['msg']}\\n{row['msg_proc_bigramms']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRanker:\n",
    "    \"\"\"\n",
    "    TextRank for keyword extraction.\n",
    "    This model builds a graph that represents the text. A graph based ranking\n",
    "    algorithm is then applied to extract the lexical units (here the words) that\n",
    "    are most important in the text.\n",
    "    In this implementation, \n",
    "     - nodes - are words of certain part-of-speech (nouns/adjectives/..) \n",
    "     - edges - represent co-occurrence relation, controlled by the distance \n",
    "               between word occurrences - a window of N words). \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ):\n",
    "        # Russian language parser\n",
    "        self.__morph = pymorphy2.MorphAnalyzer()\n",
    "        # Words graph\n",
    "        self.__graph = nx.Graph()\n",
    "        self.__texts = []  # as List[List[Dict[str, Any]]] -> [[{'words': [], 'bigramm': [], 'POS': []}]]\n",
    "        # Each inner Dict == single token\n",
    "        # Each inner List == single text\n",
    "        # Outer List is composition of texts\n",
    "        \n",
    "    def candidate_weighting(self, texts: List[List[str]],\n",
    "                            window: int=2, pos_list: List[str]=None,\n",
    "                            include_bigramms: bool=True,\n",
    "                            top_percent: float=None):\n",
    "        \"\"\"\n",
    "        Tailored candidate ranking method for TextRank. \n",
    "        Keyphrase candidates are either composed from the T-percent (top_percent) \n",
    "        highest-ranked words or extracted using the `candidate_selection()` method.\n",
    "        Candidates are ranked using the sum of their words.\n",
    "        :param window - the window for connecting words in the graph.\n",
    "        :param pos_list - the set of valid pos for words to be considered as nodes\n",
    "                    in the graph, defaults to ('NOUN', 'PROPN', 'ADJ').\n",
    "        :param top_percent - percentage of top vertices to keep for phrase generation.\n",
    "        \"\"\"\n",
    "        # flatten document as a sequence of (word, bigramm, pos) samples\n",
    "        self.__texts = self.__tag_words(texts)\n",
    "        self.__window = window\n",
    "        self.__include_bigramms = include_bigramms\n",
    "        if (pos_list is None) and ~include_bigramms:\n",
    "            # From pymorphy2 avaliable POS tags\n",
    "            # ref: http://opencorpora.org/dict.php?act=gram \n",
    "            self.__pos_list = ['NOUN', 'ADJS', 'ADJF', 'COMP', 'VERB', 'INFN', \n",
    "                               'PRTF', 'PRTS', 'GRND', 'NUMR', 'ADVB', 'Abbr']\n",
    "        else:\n",
    "            self.__pos_list = None\n",
    "            \n",
    "        self.__build_word_graph()\n",
    "    \n",
    "    \n",
    "    def __check_validness(self, token_dict: Dict[str, Any]) -> bool:\n",
    "        return token_dict['bigramm'] or any([tag in token_dict['bigramm'] \n",
    "                                         for tag in self.__pos_list])\n",
    "        \n",
    "        \n",
    "    def __tag_words(self, texts: List[List[str]]):\n",
    "        \"\"\"\n",
    "        Process given texts to selected form: \n",
    "        [[{'words': [], 'bigramm': [], 'POS': [], 'valid'}]]\n",
    "        \"\"\"\n",
    "        texts = [[{'token': token,\n",
    "                  'bigramm': True if \"_\" in token else False,\n",
    "                  'pos': self.__morph.parse(str(token).lower())[0].tag if \"_\" in token else None}\n",
    "                 for token in tokens] \n",
    "                for tokens in tqdm_notebook(texts)]\n",
    "        _ = [[token.update({'valid': self.__check_validness(token)})  \n",
    "                 for token in tokens] for tokens in tqdm_notebook(texts)]\n",
    "        return texts\n",
    "            \n",
    "            \n",
    "    def __build_word_graph(self):\n",
    "        \"\"\"\n",
    "        Build a graph representation of the document in which nodes/vertices\n",
    "        are words and edges represent co-occurrence relation. Syntactic filters\n",
    "        can be applied to select only words of certain Part-of-Speech.\n",
    "        Co-occurrence relations can be controlled using the distance between\n",
    "        word occurrences in the document.\n",
    "        \"\"\"\n",
    "        tokens = itertools.chain.from_iterable(self.__texts)\n",
    "        # add nodes to the graph\n",
    "        self.__graph.add_nodes_from([token['token'] for token in tokens if token['valid']])\n",
    "\n",
    "        # add edges to the graph\n",
    "        for text_i, tokens in enumerate(self.__texts):\n",
    "            for token_i, token in enumerate(tokens):\n",
    "                # speed up things\n",
    "                if not token['valid']:\n",
    "                    continue\n",
    "                start_ind = min(token_i, (self.__window - 1) // 2)\n",
    "                end_ind = min(i + self.__window, len(tokens))\n",
    "                for j in range(start_ind, end_ind):\n",
    "                    linked_token = tokens[j]\n",
    "                    if linked_token['valid'] and linked_token['token'] != token['token']:\n",
    "                        self.__graph.add_edge(token['token'], linked_token['token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
